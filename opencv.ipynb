{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "465a3791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 77 114 110]\n",
      "  [ 78 115 111]\n",
      "  [ 78 115 113]\n",
      "  ...\n",
      "  [195 201 200]\n",
      "  [194 200 199]\n",
      "  [194 200 199]]\n",
      "\n",
      " [[ 78 115 111]\n",
      "  [ 78 115 111]\n",
      "  [ 78 115 113]\n",
      "  ...\n",
      "  [196 202 201]\n",
      "  [197 203 202]\n",
      "  [197 203 202]]\n",
      "\n",
      " [[ 78 115 111]\n",
      "  [ 78 115 111]\n",
      "  [ 79 116 114]\n",
      "  ...\n",
      "  [193 198 197]\n",
      "  [192 197 196]\n",
      "  [192 197 196]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 41  97 168]\n",
      "  [ 37  96 166]\n",
      "  [ 39  95 166]\n",
      "  ...\n",
      "  [ 12  52 104]\n",
      "  [ 11  51 103]\n",
      "  [ 12  52 104]]\n",
      "\n",
      " [[ 34  90 167]\n",
      "  [ 31  89 164]\n",
      "  [ 32  89 164]\n",
      "  ...\n",
      "  [ 18  58 110]\n",
      "  [ 13  56 107]\n",
      "  [ 11  54 105]]\n",
      "\n",
      " [[ 26  83 162]\n",
      "  [ 23  80 159]\n",
      "  [ 22  80 156]\n",
      "  ...\n",
      "  [ 21  61 113]\n",
      "  [ 16  59 110]\n",
      "  [ 12  55 106]]]\n",
      "5760000\n",
      "uint8\n",
      "(1200, 1600, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "resim = cv2.imread(\"kedi.jpg\")#renkleri kullanmayacak 0(kanal 0)\n",
    "cv2.imshow(\"beyza\", resim)\n",
    "#matrisini yazdırma\n",
    "print(resim)\n",
    "#boyut ögrenmek\n",
    "print(resim.size)\n",
    "print(resim.dtype)#hangi data tipinde\n",
    "#resmin genişlik yükseklik ve kullandığı kanal sayısını göster\n",
    "print(resim.shape)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f247c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#brg piksel\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m kedi\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkedi.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 230 asagı 80 sag renk pikselini alıyoruz.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(kedi[(\u001b[38;5;241m230\u001b[39m,\u001b[38;5;241m80\u001b[39m)])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "#brg piksel\n",
    "kedi=cv2.imread(\"kedi.jpg\")\n",
    "\n",
    "# 230 asagı 80 sag renk pikselini alıyoruz.\n",
    "print(kedi[(230,80)])\n",
    "print(\"resim boyut: \"+str(kedi.size))\n",
    "print(\"resim özellik: \"+str(kedi.shape))\n",
    "print(\"resim veri tipi: \"+str(kedi.dtype))\n",
    "for i in range(100):\n",
    "    kedi[i+20,100]=[0,0,255]\n",
    "    \n",
    "\n",
    "cv2.imshow(\"kedi\",kedi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3292f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#secili kısıma efekt\n",
    "kedi=cv2.imread(\"43.jpg\")\n",
    "kedi[150:500,50:500,0]=150\n",
    "#kedi[:,:,1]=255\n",
    "#kedi[:,:,1]=150\n",
    "cv2.imshow(\"kedi\",kedi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a9dfa0",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f85a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#secili kısıma yapıstır kırp efekt\n",
    "kedi=cv2.imread(\"43.jpg\")\n",
    "resim=kedi[30:130,40:140]\n",
    "kedi[0:100,0:100]=resim\n",
    "kedi[0:400,0:250]=(0,200,200)\n",
    "kedi[150:500,50:500,0]=150\n",
    "#kedi[:,:,1]=255\n",
    "#kedi[:,:,1]=150\n",
    "cv2.imshow(\"kedi\",kedi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eca3efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "kedi=cv2.imread(\"f.jpg\")\n",
    "aynala=cv2.copyMakeBorder(kedi,125,125,300,300,cv2.BORDER_REFLECT)\n",
    "uzat=cv2.copyMakeBorder(kedi,100,100,20,20,cv2.BORDER_REPLICATE)\n",
    "tekrar=cv2.copyMakeBorder(kedi,125,125,300,300,cv2.BORDER_WRAP)\n",
    "sarilan=cv2.copyMakeBorder(kedi,50,50,50,50,cv2.BORDER_CONSTANT ,value=(0,20,120))\n",
    "#cv2.imshow(\"aynala\",aynala)\n",
    "#cv2.imshow(\"uzat\",uzat)\n",
    "cv2.imshow(\"sar\",sarilan)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ffa1855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222 103 207]\n"
     ]
    }
   ],
   "source": [
    "#ağırlıklı toplama\n",
    "import cv2\n",
    "import numpy as np\n",
    "kedi=cv2.imread(\"r.jpg\")\n",
    "print(kedi[100,200]+kedi[300,200])\n",
    "kedi[50:100,200:250]=(220,240,250)\n",
    "cv2.imshow(\"res\",kedi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "001f853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ağırlıklı toplama birbirleriyle birleştirme\n",
    "import cv2\n",
    "import numpy as np\n",
    "resim1=cv2.imread(\"r.jpg\")\n",
    "resim2=cv2.imread(\"f.jpg\")\n",
    "toplam=cv2.add(resim1,resim2)\n",
    "agietop=cv2.addWeighted(resim1,0.7,resim2,0.3,0)\n",
    "cv2.imshow(\"topla\",toplam)\n",
    "cv2.imshow(\"res\",agietop)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d820040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orj 600 600 3\n",
      "orj 600 600\n"
     ]
    }
   ],
   "source": [
    "#resimi grileştirme\n",
    "import cv2\n",
    "import numpy as np\n",
    "resim1=cv2.imread(\"r.jpg\")\n",
    "yuk,gen,kanal=resim1.shape\n",
    "print(\"orj\",yuk,gen,kanal)\n",
    "gri=cv2.cvtColor(resim1,cv2.COLOR_BGR2GRAY)\n",
    "yuk1,gen1=gri.shape\n",
    "print(\"orj\",yuk1,gen1)\n",
    "cv2.imshow(\"topla\",resim1)\n",
    "cv2.imshow(\"res\",gri)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22f3ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#buyut kucult\n",
    "import cv2\n",
    "import numpy as np\n",
    "resim1=cv2.imread(\"r.jpg\")\n",
    "buyuk=cv2.pyrUp(resim1)\n",
    "kucuk=cv2.pyrDown(resim1)\n",
    "cv2.imshow(\"res\",buyuk)\n",
    "#cv2.imshow(\"res\",kucuk)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3323c3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 64 109 153]\n",
      "[ 65 108 154]\n",
      "[ 66 109 155]\n",
      "[ 65 109 155]\n"
     ]
    }
   ],
   "source": [
    "#gurultu azaltma için filtreleme\n",
    "resim=cv2.imread(\"43.jpg\")\n",
    "meanf=cv2.blur(resim,(5,5))\n",
    "median=cv2.medianBlur(resim,5)\n",
    "gauss=cv2.GaussianBlur(resim,(5,5),0)\n",
    "\n",
    "cv2.imshow(\"orj\",resim)\n",
    "cv2.imshow(\"ort\",meanf)\n",
    "cv2.imshow(\"medyan\",median)\n",
    "cv2.imshow(\"gauss\",gauss)\n",
    "print(resim[400,250])\n",
    "print(meanf[400,250])\n",
    "print(median[400,250])#****\n",
    "print(gauss[400,250])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "75c38cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genişlet-daralt gurultu\n",
    "resim=cv2.imread(\"43.jpg\")\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "erasion=cv2.erode(resim,kernel,iterations=2)\n",
    "delation=cv2.dilate(resim,kernel,iterations=1)\n",
    "#delation=cv2.dilate(erasion,kernel,iterations=1) gürültü azaltıp kalınlaştırma temiz görüntü elde etmek için\n",
    "cv2.imshow(\"orj\",resim)\n",
    "cv2.imshow(\"r\",erasion)\n",
    "cv2.imshow(\"d\",delation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228aeda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genişlet-daralt gurultu\n",
    "image=cv2.imread(\"43.jpg\")\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "opening=cv2.morphologyEx(image,cv2.MORPH_OPEN,kernel)\n",
    "closing=cv2.morphologyEx(image,cv2.MORPH_CLOSE,kernel)\n",
    "gradyan=cv2.morphologyEx(image,cv2.MORPH_GRADIENT,kernel)\n",
    "tophat=cv2.morphologyEx(image,cv2.MORPH_TOPHAT,kernel)\n",
    "blackhat=cv2.morphologyEx(image,cv2.MORPH_BLACKHAT,kernel)\n",
    "cv2.imshow(\"orj\",image)\n",
    "cv2.imshow(\"o\",opening)\n",
    "cv2.imshow(\"c\",closing)\n",
    "cv2.imshow(\"g\",gradyan)\n",
    "cv2.imshow(\"t\",tophat)\n",
    "cv2.imshow(\"b\",blackhat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0c43ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(\"43.jpg\")\n",
    "resim=cv2.imread(\"r.jpg\")\n",
    "f=cv2.imread(\"f.jpg\")\n",
    "ret,thresh1=cv2.threshold(image,127,180,cv2.THRESH_BINARY)\n",
    "ret,thresh2=cv2.threshold(image,150,250,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3=cv2.threshold(image,127,180,cv2.THRESH_TRUNC)\n",
    "ret,thresh4=cv2.threshold(image,127,180,cv2.THRESH_TOZERO)\n",
    "ret,thresh5=cv2.threshold(image,150,250,cv2.THRESH_TOZERO_INV)\n",
    "ret,thresh6=cv2.threshold(resim,150,250,cv2.THRESH_TOZERO_INV)\n",
    "ret,thresh7=cv2.threshold(resim,150,250,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh8=cv2.threshold(f,150,250,cv2.THRESH_TOZERO_INV)\n",
    "ret,thresh9=cv2.threshold(f,150,250,cv2.THRESH_BINARY_INV)\n",
    "#cv2.imshow(\"orj\",image)\n",
    "#cv2.imshow(\"orj\",resim)\n",
    "#cv2.imshow(\"orj\",f)\n",
    "cv2.imshow(\"6\",thresh6)\n",
    "#cv2.imshow(\"7\",thresh7)\n",
    "#cv2.imshow(\"2\",thresh2)\n",
    "cv2.imshow(\"8\",thresh8)\n",
    "#cv2.imshow(\"9\",thresh9)\n",
    "#cv2.imshow(\"4\",thresh4)\n",
    "cv2.imshow(\"5\",thresh5)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12289478",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(\"43.jpg\",0)\n",
    "resim=cv2.imread(\"r.jpg\",0)\n",
    "f=cv2.imread(\"f.jpg\",0)\n",
    "ret,thresh1=cv2.threshold(image,127,180,cv2.THRESH_BINARY)\n",
    "thresh2=cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "thresh3=cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "thresh4=cv2.adaptiveThreshold(resim,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "thresh5=cv2.adaptiveThreshold(resim,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "thresh6=cv2.adaptiveThreshold(f,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "thresh7=cv2.adaptiveThreshold(f,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "cv2.imshow(\"1\",thresh1)\n",
    "cv2.imshow(\"2\",thresh2)\n",
    "cv2.imshow(\"3\",thresh3)\n",
    "cv2.imshow(\"4\",thresh4)\n",
    "cv2.imshow(\"5\",thresh5)\n",
    "cv2.imshow(\"6\",thresh6)\n",
    "cv2.imshow(\"7\",thresh7)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b5709ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread(\"r.jpg\",0)\n",
    "blur=cv2.GaussianBlur(image,(3,3),0)\n",
    "cv2.imshow(\"blur\",blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f26c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread(\"r.jpg\")\n",
    "resim=cv2.imread(\"r.jpg\")\n",
    "bit_And=cv2.bitwise_and(image,resim)\n",
    "cv2.imshow(\"bitand\",bit_And)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd782bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iki resmin arasındaki fark\n",
    "import cv2\n",
    "resim=cv2.imread(\"43.jpg\")\n",
    "img=cv2.imread(\"r.jpg\")\n",
    "bir=cv2.subtract(resim,img)\n",
    "cv2.imshow(\"s\",bir)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5a454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1997 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# VGG16 modelini oluştur\n",
    "vgg_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# MobileNetV3-Small modelini oluştur\n",
    "mobilenet_model = tf.keras.applications.MobileNetV3Small( input_shape=(224, 224, 3),  # Giriş şeklini ayarlayın\n",
    "    minimalistic=False,\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "for layer in mobilenet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# İki modeli birleştir\n",
    "combined_model = tf.keras.Sequential([\n",
    "    vgg_model,\n",
    "    mobilenet_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Modeli derle\n",
    "combined_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Veri yolu tanımları\n",
    "egitim = r'C:\\Users\\06bey\\zor\\egitim'\n",
    "val = r'C:\\Users\\06bey\\zor\\val'\n",
    "test = r'C:\\Users\\06bey\\zor\\test'\n",
    "preprocess_input = tf.keras.applications.mobilenet_v3.preprocess_input \n",
    "\n",
    "# Veri artırma\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input \n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    egitim, \n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',  # İkili sınıflandırma olduğunu belirtin\n",
    "  \n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val, \n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',  # İkili sınıflandırma olduğunu belirtin\n",
    ")\n",
    "\n",
    "# Modeli eğit\n",
    "history = combined_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=6,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "# Modeli kaydet\n",
    "combined_model.save('combined_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# VGG16 modelini yükleyelim\n",
    "conv_base = tf.keras.applications.VGG16(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# VGG16 modelinin belirli bir katmanına kadar olan ağırlıkları dondurma\n",
    "conv_base.trainable = False\n",
    "\n",
    "# MobilenetV3Small modelini yükleyelim\n",
    "mobilenet_model = tf.keras.applications.MobileNetV3Small(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# MobilenetV3Small modelinin belirli bir katmanına kadar olan ağırlıkları dondurma\n",
    "for layer in mobilenet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "resize_layer = tf.keras.layers.Conv2D(3, (1, 1), activation='relu')\n",
    "\n",
    "# Modeli oluşturalım\n",
    "model = tf.keras.Sequential([\n",
    "    conv_base,\n",
    "    resize_layer,\n",
    "    tf.keras.layers.UpSampling2D(size=(32, 32)),  # Çıkış boyutunu (224, 224, 3) haline getiriyoruz\n",
    "    mobilenet_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Modeli derleyelim\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Modelin özeti\n",
    "model.summary()\n",
    "\n",
    "# Veri yolları\n",
    "egitim = r'C:\\Users\\06bey\\zor\\egitim'\n",
    "val = r'C:\\Users\\06bey\\zor\\val'\n",
    "test = r'C:\\Users\\06bey\\zor\\test' # Test veri yolu tanımlayalım\n",
    "\n",
    "# Veri artırma ve veri akışlarını oluşturalım\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1.0 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    egitim, \n",
    "    target_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val, \n",
    "    target_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Modeli eğitelim\n",
    "egit = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "# Eğitim sürecinde elde edilen metrikleri al\n",
    "train_accuracy = egit.history['accuracy']\n",
    "val_accuracy = egit.history['val_accuracy']\n",
    "train_loss = egit.history['loss']\n",
    "val_loss = egit.history['val_loss']\n",
    "\n",
    "# Grafik oluştur\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Doğruluk grafiği\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accuracy, label='Training Accuracy', color='blue')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy', color='red')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Kayıp grafiği\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Training Loss', color='blue')\n",
    "plt.plot(val_loss, label='Validation Loss', color='red')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Grafikleri göster\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Modeli kaydet\n",
    "model.save('yuz_ayirt_et.keras')\n",
    "\n",
    "# Test veri akışını oluşturalım\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "# Test verisi üzerinde modeli değerlendirme\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220202a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
